{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/bs4/css.py:8: UserWarning: The soupsieve package is not installed. CSS selectors cannot be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully scraped 2015\n",
      "✅ Successfully scraped 2016\n",
      "✅ Successfully scraped 2017\n",
      "✅ Successfully scraped 2018\n",
      "✅ Successfully scraped 2019\n",
      "✅ Successfully scraped 2020\n",
      "✅ Successfully scraped 2021\n",
      "✅ Successfully scraped 2022\n",
      "✅ Successfully scraped 2023\n",
      "✅ Successfully scraped 2024\n",
      "✅ Successfully scraped 2025\n",
      "✅ Data saved to google_trends_year_in_search.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL pattern for Google Trends Year in Search\n",
    "base_url = \"https://trends.withgoogle.com/year-in-search/{year}/us/\"\n",
    "\n",
    "# List to store all data\n",
    "all_data = []\n",
    "\n",
    "# Loop through each year from 2015 to 2025\n",
    "for year in range(2015, 2026):\n",
    "    url = base_url.format(year=year)\n",
    "    \n",
    "    try:\n",
    "        # Fetch the webpage content\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Find all category containers\n",
    "        categories = soup.find_all(\"div\", class_=\"card-inner-container\")\n",
    "\n",
    "        for category in categories:\n",
    "            # Extract the category title\n",
    "            title_tag = category.find(\"h4\", class_=\"glue-headline--headline-4\")\n",
    "            if title_tag:\n",
    "                category_title = title_tag.text.strip()\n",
    "            else:\n",
    "                continue  # Skip if no title found\n",
    "\n",
    "            # Extract the list items within the category\n",
    "            items = category.find_all(\"li\", class_=\"glue-card__list-item\")\n",
    "            for rank, item in enumerate(items, start=1):\n",
    "                # Extract only the text inside the search term\n",
    "                term_tag = item.find(\"h4\")  # The actual trending search term is inside <h4>\n",
    "                if term_tag:\n",
    "                    search_term = term_tag.text.strip()\n",
    "                else:\n",
    "                    search_term = item.get_text(strip=True).split(\"Search it\")[0].strip()  # Remove \"Search it\" text\n",
    "\n",
    "                all_data.append([year, category_title, rank, search_term])\n",
    "    \n",
    "        print(f\"✅ Successfully scraped {year}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to scrape {year}: {e}\")\n",
    "\n",
    "# Create a DataFrame\n",
    "df_trending_searches = pd.DataFrame(all_data, columns=[\"Year\", \"Category\", \"Rank\", \"Search Term\"])\n",
    "\n",
    "print(f\"✅ Data saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from IPython.display import display, HTML  # Corrected import\n",
    "\n",
    "# # Save DataFrame as a CSV file\n",
    "# csv_filename = \"google_trending_searches_2015_2025.csv\"\n",
    "# df_trending_searches.to_csv(csv_filename, index=False)\n",
    "# print(f\"✅ Data saved as '{csv_filename}'\")\n",
    "\n",
    "# # Generate HTML table with scrollable container\n",
    "# scrollable_table_html = f\"\"\"\n",
    "# <style>\n",
    "#     .scrollable-table {{\n",
    "#         overflow-y: auto;\n",
    "#         height: 500px;\n",
    "#         display: block;\n",
    "#         border: 1px solid #ddd;\n",
    "#     }}\n",
    "#     table {{\n",
    "#         border-collapse: collapse;\n",
    "#         width: 100%;\n",
    "#     }}\n",
    "#     th, td {{\n",
    "#         border: 1px solid #ddd;\n",
    "#         padding: 8px;\n",
    "#         text-align: left;\n",
    "#     }}\n",
    "#     th {{\n",
    "#         background-color: #f4f4f4;\n",
    "#         position: sticky;\n",
    "#         top: 0;\n",
    "#     }}\n",
    "# </style>\n",
    "# <div class=\"scrollable-table\">\n",
    "#     {df_trending_searches.to_html(index=False, classes='table table-striped table-hover')}\n",
    "# </div>\n",
    "# \"\"\"\n",
    "\n",
    "# # Display the scrollable table\n",
    "# display(HTML(scrollable_table_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekly Search Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found existing data: 1171 search terms already processed.\n",
      "❌ Attempt 1/3 failed for Duke Blue Devils Men's Basketball (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 2/3 failed for Duke Blue Devils Men's Basketball (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 3/3 failed for Duke Blue Devils Men's Basketball (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 1/3 failed for Lenny Kravitz (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 2/3 failed for Lenny Kravitz (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 3/3 failed for Lenny Kravitz (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 1/3 failed for Nicole Curtis (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 2/3 failed for Nicole Curtis (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 3/3 failed for Nicole Curtis (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 1/3 failed for Eddie Redmayne (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 2/3 failed for Eddie Redmayne (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 3/3 failed for Eddie Redmayne (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 1/3 failed for That's Racist (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 2/3 failed for That's Racist (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 3/3 failed for That's Racist (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 1/3 failed for Ben Zobrist (2015): The request failed: Google returned a response with code 429\n",
      "❌ Attempt 2/3 failed for Ben Zobrist (2015): The request failed: Google returned a response with code 429\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Get interest over time\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m df_trends \u001b[38;5;241m=\u001b[39m \u001b[43mpytrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Remove 'isPartial' column if present\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:232\u001b[0m, in \u001b[0;36mTrendReq.interest_over_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m req_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(req_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimelineData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:159\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[0;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 74\u001b[0m\n\u001b[1;32m     72\u001b[0m         attempt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Attempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_term\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Exponential backoff (5s, 10s, 15s)\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:  \u001b[38;5;66;03m# If all retries failed, add to failed list\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     failed_terms\u001b[38;5;241m.\u001b[39mappend((search_term, year))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Load processed data if it exists\n",
    "clean_data_file = \"clean_trends_data.csv\"\n",
    "failed_data_file = \"failed_terms.csv\"\n",
    "\n",
    "# Load existing clean data\n",
    "if os.path.exists(clean_data_file):\n",
    "    df_existing = pd.read_csv(clean_data_file)\n",
    "    completed_terms = set(df_existing[\"Search Term\"].unique())\n",
    "    print(f\"✅ Found existing data: {len(completed_terms)} search terms already processed.\")\n",
    "else:\n",
    "    df_existing = pd.DataFrame()\n",
    "    completed_terms = set()\n",
    "\n",
    "# Load the first 50 rows from the CSV for testing\n",
    "input_csv = \"google_trending_searches_2015_2025_x.csv\"\n",
    "df_trending_searches_processed = pd.read_csv(input_csv)\n",
    "\n",
    "# Initialize Pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360, retries=3)\n",
    "\n",
    "# Prepare storage for results\n",
    "all_trends = []\n",
    "\n",
    "# Extract search terms that still need to be processed\n",
    "pending_terms = [\n",
    "    (row[\"Search Term\"], str(row[\"Year\"])) for _, row in df_trending_searches_processed.iterrows()\n",
    "    if row[\"Search Term\"] not in completed_terms\n",
    "]\n",
    "\n",
    "max_retries = 3  # Maximum retries per search term\n",
    "\n",
    "while pending_terms:\n",
    "    failed_terms = []  # Reset failed terms list in each loop\n",
    "\n",
    "    for search_term, year in pending_terms:\n",
    "        attempt = 0\n",
    "        success = False\n",
    "\n",
    "        while attempt < max_retries and not success:\n",
    "            try:\n",
    "                # Build payload for a single search term\n",
    "                pytrends.build_payload([search_term], timeframe=f\"{year}-01-01 {year}-12-31\", geo='US')\n",
    "\n",
    "                # Get interest over time\n",
    "                df_trends = pytrends.interest_over_time()\n",
    "\n",
    "                # Remove 'isPartial' column if present\n",
    "                if 'isPartial' in df_trends.columns:\n",
    "                    df_trends = df_trends.drop(columns=['isPartial'])\n",
    "\n",
    "                # Convert data to long format (Tidy Data)\n",
    "                df_trends = df_trends.reset_index().melt(id_vars=[\"date\"], var_name=\"Search Term\", value_name=\"Interest\")\n",
    "\n",
    "                # Add metadata columns\n",
    "                df_trends[\"Year\"] = year\n",
    "\n",
    "                # Append results\n",
    "                all_trends.append(df_trends)\n",
    "\n",
    "                print(f\"✅ Extracted: {search_term} ({year})\")\n",
    "                success = True  # Mark as success\n",
    "\n",
    "                # Save progress after every search term\n",
    "                pd.concat(all_trends + [df_existing], ignore_index=True).to_csv(clean_data_file, index=False)\n",
    "\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                print(f\"❌ Attempt {attempt}/{max_retries} failed for {search_term} ({year}): {e}\")\n",
    "                time.sleep(5 * attempt)  # Exponential backoff (5s, 10s, 15s)\n",
    "\n",
    "        if not success:  # If all retries failed, add to failed list\n",
    "            failed_terms.append((search_term, year))\n",
    "\n",
    "    # Update pending terms for the next loop (only failed ones)\n",
    "    pending_terms = failed_terms  \n",
    "\n",
    "    if pending_terms:\n",
    "        print(f\"🔄 Retrying {len(pending_terms)} failed terms...\")\n",
    "\n",
    "# If all terms are processed, remove the failed_terms.csv\n",
    "if os.path.exists(failed_data_file):\n",
    "    os.remove(failed_data_file)\n",
    "\n",
    "print(\"✅ All terms successfully processed! Check clean_trends_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  Donald Trump  Wikipedia\n",
      "0 2017-01-01            27         17\n",
      "1 2017-01-08            48         18\n",
      "2 2017-01-15           100         18\n",
      "3 2017-01-22            79         20\n",
      "4 2017-01-29            64         19\n"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Define Keywords for comparison\n",
    "keywords = [\"Donald Trump\", \"Wikipedia\"]\n",
    "\n",
    "# Build Payload\n",
    "pytrends.build_payload(keywords, timeframe='2017-01-01 2017-12-31', geo='US')\n",
    "\n",
    "# Get weekly interest over time\n",
    "df_trends = pytrends.interest_over_time()\n",
    "\n",
    "# Remove 'isPartial' column if present\n",
    "if 'isPartial' in df_trends.columns:\n",
    "    df_trends = df_trends.drop(columns=['isPartial'])\n",
    "\n",
    "# Reset index to include date as a column\n",
    "df_trends.reset_index(inplace=True)\n",
    "\n",
    "print(df_trends.head())  # Show first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequestsError",
     "evalue": "The request failed: Google returned a response with code 429",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m pytrends\u001b[38;5;241m.\u001b[39mbuild_payload(keywords, timeframe\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2017-01-01 2017-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m, geo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Get weekly interest over time\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m df_trends \u001b[38;5;241m=\u001b[39m \u001b[43mpytrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Remove 'isPartial' column if present\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misPartial\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_trends\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:232\u001b[0m, in \u001b[0;36mTrendReq.interest_over_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m over_time_payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# convert to string as requests will mangle\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreq\u001b[39m\u001b[38;5;124m'\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtz\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz\n\u001b[1;32m    229\u001b[0m }\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m req_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(req_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimelineData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (df\u001b[38;5;241m.\u001b[39mempty):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:159\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[0;32m--> 159\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[0;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Define Keywords for comparison\n",
    "keywords = [\"Donald Trump\", \"Wikipedia\"]\n",
    "\n",
    "# Build Payload\n",
    "pytrends.build_payload(keywords, timeframe='2017-01-01 2017-12-31', geo='US')\n",
    "\n",
    "# Get weekly interest over time\n",
    "df_trends = pytrends.interest_over_time()\n",
    "\n",
    "# Remove 'isPartial' column if present\n",
    "if 'isPartial' in df_trends.columns:\n",
    "    df_trends = df_trends.drop(columns=['isPartial'])\n",
    "\n",
    "# Reset index to include date as a column\n",
    "df_trends.reset_index(inplace=True)\n",
    "\n",
    "print(df_trends.head())  # Show first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequestsError",
     "evalue": "The request failed: Google returned a response with code 429",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m pytrends\u001b[38;5;241m.\u001b[39mbuild_payload(keywords, timeframe\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2015-01-01 2015-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m, geo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Get weekly interest over time\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m df_trends \u001b[38;5;241m=\u001b[39m \u001b[43mpytrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Remove 'isPartial' column if present\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misPartial\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_trends\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:232\u001b[0m, in \u001b[0;36mTrendReq.interest_over_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m over_time_payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# convert to string as requests will mangle\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreq\u001b[39m\u001b[38;5;124m'\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtz\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz\n\u001b[1;32m    229\u001b[0m }\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m req_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(req_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimelineData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (df\u001b[38;5;241m.\u001b[39mempty):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:159\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[0;32m--> 159\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[0;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Define Keywords for comparison\n",
    "keywords = [\"Bernie Sanders\"]\n",
    "\n",
    "# Build Payload\n",
    "pytrends.build_payload(keywords, timeframe='2015-01-01 2015-12-31', geo='US')\n",
    "\n",
    "# Get weekly interest over time\n",
    "df_trends = pytrends.interest_over_time()\n",
    "\n",
    "# Remove 'isPartial' column if present\n",
    "if 'isPartial' in df_trends.columns:\n",
    "    df_trends = df_trends.drop(columns=['isPartial'])\n",
    "\n",
    "# Reset index to include date as a column\n",
    "df_trends.reset_index(inplace=True)\n",
    "\n",
    "print(df_trends.head())  # Show first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annualised Comp to Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Search Term  Average Interest  Year\n",
      "0  Donald Trump         27.000000  2017\n",
      "1     Wikipedia         17.660377  2017\n"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Define Keywords for comparison\n",
    "keywords = [\"Donald Trump\", \"Wikipedia\"]\n",
    "\n",
    "# Define Year\n",
    "year = \"2017\"\n",
    "\n",
    "# Build Payload\n",
    "pytrends.build_payload(keywords, timeframe=f\"{year}-01-01 {year}-12-31\", geo='US')\n",
    "\n",
    "# Get weekly interest over time\n",
    "df_trends = pytrends.interest_over_time()\n",
    "\n",
    "# Remove 'isPartial' column if present\n",
    "if 'isPartial' in df_trends.columns:\n",
    "    df_trends = df_trends.drop(columns=['isPartial'])\n",
    "\n",
    "# Compute the yearly average interest\n",
    "df_average_interest = df_trends.mean().reset_index()\n",
    "df_average_interest.columns = [\"Search Term\", \"Average Interest\"]\n",
    "\n",
    "# Add Year column\n",
    "df_average_interest[\"Year\"] = year\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_average_interest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract State Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Define Keywords\n",
    "keywords = [\"Kevin Spacey\", \"Wikipedia\"]\n",
    "\n",
    "# Build Payload for comparison\n",
    "pytrends.build_payload(keywords, timeframe='2017-01-01 2017-12-31', geo='US')\n",
    "\n",
    "# Extract Regional Interest\n",
    "df_regions = pytrends.interest_by_region(resolution='REGION')\n",
    "\n",
    "# Normalize as percentages\n",
    "df_regions[\"Total\"] = df_regions.sum(axis=1)\n",
    "df_regions[\"Kevin Spacey %\"] = (df_regions[\"Kevin Spacey\"] / df_regions[\"Total\"]) * 100\n",
    "df_regions[\"Wikipedia %\"] = (df_regions[\"Wikipedia\"] / df_regions[\"Total\"]) * 100\n",
    "\n",
    "# Keep only percentage columns\n",
    "df_regions = df_regions[[\"Kevin Spacey %\", \"Wikipedia %\"]]\n",
    "\n",
    "# Save to CSV\n",
    "df_regions.to_csv(\"state_interest_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequestsError",
     "evalue": "The request failed: Google returned a response with code 429",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m pytrends \u001b[38;5;241m=\u001b[39m TrendReq(hl\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men-US\u001b[39m\u001b[38;5;124m'\u001b[39m, tz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m360\u001b[39m)\n\u001b[1;32m      5\u001b[0m pytrends\u001b[38;5;241m.\u001b[39mbuild_payload([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoogle\u001b[39m\u001b[38;5;124m\"\u001b[39m], timeframe\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnow 1-d\u001b[39m\u001b[38;5;124m\"\u001b[39m, geo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m df_trends \u001b[38;5;241m=\u001b[39m \u001b[43mpytrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_trends\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:232\u001b[0m, in \u001b[0;36mTrendReq.interest_over_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m over_time_payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# convert to string as requests will mangle\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreq\u001b[39m\u001b[38;5;124m'\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtz\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz\n\u001b[1;32m    229\u001b[0m }\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m req_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(req_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimelineData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (df\u001b[38;5;241m.\u001b[39mempty):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:159\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[0;32m--> 159\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[0;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "pytrends.build_payload([\"Google\"], timeframe=\"now 1-d\", geo='US')\n",
    "\n",
    "df_trends = pytrends.interest_over_time()\n",
    "print(df_trends.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
