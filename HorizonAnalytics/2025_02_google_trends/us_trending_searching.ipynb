{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/bs4/css.py:8: UserWarning: The soupsieve package is not installed. CSS selectors cannot be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully scraped 2015\n",
      "‚úÖ Successfully scraped 2016\n",
      "‚úÖ Successfully scraped 2017\n",
      "‚úÖ Successfully scraped 2018\n",
      "‚úÖ Successfully scraped 2019\n",
      "‚úÖ Successfully scraped 2020\n",
      "‚úÖ Successfully scraped 2021\n",
      "‚úÖ Successfully scraped 2022\n",
      "‚úÖ Successfully scraped 2023\n",
      "‚úÖ Successfully scraped 2024\n",
      "‚úÖ Successfully scraped 2025\n",
      "‚úÖ Data saved to google_trends_year_in_search.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL pattern for Google Trends Year in Search\n",
    "base_url = \"https://trends.withgoogle.com/year-in-search/{year}/us/\"\n",
    "\n",
    "# List to store all data\n",
    "all_data = []\n",
    "\n",
    "# Loop through each year from 2015 to 2025\n",
    "for year in range(2015, 2026):\n",
    "    url = base_url.format(year=year)\n",
    "    \n",
    "    try:\n",
    "        # Fetch the webpage content\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Find all category containers\n",
    "        categories = soup.find_all(\"div\", class_=\"card-inner-container\")\n",
    "\n",
    "        for category in categories:\n",
    "            # Extract the category title\n",
    "            title_tag = category.find(\"h4\", class_=\"glue-headline--headline-4\")\n",
    "            if title_tag:\n",
    "                category_title = title_tag.text.strip()\n",
    "            else:\n",
    "                continue  # Skip if no title found\n",
    "\n",
    "            # Extract the list items within the category\n",
    "            items = category.find_all(\"li\", class_=\"glue-card__list-item\")\n",
    "            for rank, item in enumerate(items, start=1):\n",
    "                # Extract only the text inside the search term\n",
    "                term_tag = item.find(\"h4\")  # The actual trending search term is inside <h4>\n",
    "                if term_tag:\n",
    "                    search_term = term_tag.text.strip()\n",
    "                else:\n",
    "                    search_term = item.get_text(strip=True).split(\"Search it\")[0].strip()  # Remove \"Search it\" text\n",
    "\n",
    "                all_data.append([year, category_title, rank, search_term])\n",
    "    \n",
    "        print(f\"‚úÖ Successfully scraped {year}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to scrape {year}: {e}\")\n",
    "\n",
    "# Create a DataFrame\n",
    "df_trending_searches = pd.DataFrame(all_data, columns=[\"Year\", \"Category\", \"Rank\", \"Search Term\"])\n",
    "\n",
    "print(f\"‚úÖ Data saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from IPython.display import display, HTML  # Corrected import\n",
    "\n",
    "# # Save DataFrame as a CSV file\n",
    "# csv_filename = \"google_trending_searches_2015_2025.csv\"\n",
    "# df_trending_searches.to_csv(csv_filename, index=False)\n",
    "# print(f\"‚úÖ Data saved as '{csv_filename}'\")\n",
    "\n",
    "# # Generate HTML table with scrollable container\n",
    "# scrollable_table_html = f\"\"\"\n",
    "# <style>\n",
    "#     .scrollable-table {{\n",
    "#         overflow-y: auto;\n",
    "#         height: 500px;\n",
    "#         display: block;\n",
    "#         border: 1px solid #ddd;\n",
    "#     }}\n",
    "#     table {{\n",
    "#         border-collapse: collapse;\n",
    "#         width: 100%;\n",
    "#     }}\n",
    "#     th, td {{\n",
    "#         border: 1px solid #ddd;\n",
    "#         padding: 8px;\n",
    "#         text-align: left;\n",
    "#     }}\n",
    "#     th {{\n",
    "#         background-color: #f4f4f4;\n",
    "#         position: sticky;\n",
    "#         top: 0;\n",
    "#     }}\n",
    "# </style>\n",
    "# <div class=\"scrollable-table\">\n",
    "#     {df_trending_searches.to_html(index=False, classes='table table-striped table-hover')}\n",
    "# </div>\n",
    "# \"\"\"\n",
    "\n",
    "# # Display the scrollable table\n",
    "# display(HTML(scrollable_table_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekly Search Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found existing data: 1171 search terms already processed.\n",
      "‚ùå Attempt 1/3 failed for Duke Blue Devils Men's Basketball (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 2/3 failed for Duke Blue Devils Men's Basketball (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 3/3 failed for Duke Blue Devils Men's Basketball (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 1/3 failed for Lenny Kravitz (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 2/3 failed for Lenny Kravitz (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 3/3 failed for Lenny Kravitz (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 1/3 failed for Nicole Curtis (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 2/3 failed for Nicole Curtis (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 3/3 failed for Nicole Curtis (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 1/3 failed for Eddie Redmayne (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 2/3 failed for Eddie Redmayne (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 3/3 failed for Eddie Redmayne (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 1/3 failed for That's Racist (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 2/3 failed for That's Racist (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 3/3 failed for That's Racist (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 1/3 failed for Ben Zobrist (2015): The request failed: Google returned a response with code 429\n",
      "‚ùå Attempt 2/3 failed for Ben Zobrist (2015): The request failed: Google returned a response with code 429\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Get interest over time\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m df_trends \u001b[38;5;241m=\u001b[39m \u001b[43mpytrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Remove 'isPartial' column if present\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:232\u001b[0m, in \u001b[0;36mTrendReq.interest_over_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m req_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(req_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimelineData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:159\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[0;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 74\u001b[0m\n\u001b[1;32m     72\u001b[0m         attempt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ùå Attempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_term\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Exponential backoff (5s, 10s, 15s)\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:  \u001b[38;5;66;03m# If all retries failed, add to failed list\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     failed_terms\u001b[38;5;241m.\u001b[39mappend((search_term, year))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Load processed data if it exists\n",
    "clean_data_file = \"clean_trends_data.csv\"\n",
    "failed_data_file = \"failed_terms.csv\"\n",
    "\n",
    "# Load existing clean data\n",
    "if os.path.exists(clean_data_file):\n",
    "    df_existing = pd.read_csv(clean_data_file)\n",
    "    completed_terms = set(df_existing[\"Search Term\"].unique())\n",
    "    print(f\"‚úÖ Found existing data: {len(completed_terms)} search terms already processed.\")\n",
    "else:\n",
    "    df_existing = pd.DataFrame()\n",
    "    completed_terms = set()\n",
    "\n",
    "# Load the first 50 rows from the CSV for testing\n",
    "input_csv = \"google_trending_searches_2015_2025_x.csv\"\n",
    "df_trending_searches_processed = pd.read_csv(input_csv)\n",
    "\n",
    "# Initialize Pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360, retries=3)\n",
    "\n",
    "# Prepare storage for results\n",
    "all_trends = []\n",
    "\n",
    "# Extract search terms that still need to be processed\n",
    "pending_terms = [\n",
    "    (row[\"Search Term\"], str(row[\"Year\"])) for _, row in df_trending_searches_processed.iterrows()\n",
    "    if row[\"Search Term\"] not in completed_terms\n",
    "]\n",
    "\n",
    "max_retries = 3  # Maximum retries per search term\n",
    "\n",
    "while pending_terms:\n",
    "    failed_terms = []  # Reset failed terms list in each loop\n",
    "\n",
    "    for search_term, year in pending_terms:\n",
    "        attempt = 0\n",
    "        success = False\n",
    "\n",
    "        while attempt < max_retries and not success:\n",
    "            try:\n",
    "                # Build payload for a single search term\n",
    "                pytrends.build_payload([search_term], timeframe=f\"{year}-01-01 {year}-12-31\", geo='US')\n",
    "\n",
    "                # Get interest over time\n",
    "                df_trends = pytrends.interest_over_time()\n",
    "\n",
    "                # Remove 'isPartial' column if present\n",
    "                if 'isPartial' in df_trends.columns:\n",
    "                    df_trends = df_trends.drop(columns=['isPartial'])\n",
    "\n",
    "                # Convert data to long format (Tidy Data)\n",
    "                df_trends = df_trends.reset_index().melt(id_vars=[\"date\"], var_name=\"Search Term\", value_name=\"Interest\")\n",
    "\n",
    "                # Add metadata columns\n",
    "                df_trends[\"Year\"] = year\n",
    "\n",
    "                # Append results\n",
    "                all_trends.append(df_trends)\n",
    "\n",
    "                print(f\"‚úÖ Extracted: {search_term} ({year})\")\n",
    "                success = True  # Mark as success\n",
    "\n",
    "                # Save progress after every search term\n",
    "                pd.concat(all_trends + [df_existing], ignore_index=True).to_csv(clean_data_file, index=False)\n",
    "\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                print(f\"‚ùå Attempt {attempt}/{max_retries} failed for {search_term} ({year}): {e}\")\n",
    "                time.sleep(5 * attempt)  # Exponential backoff (5s, 10s, 15s)\n",
    "\n",
    "        if not success:  # If all retries failed, add to failed list\n",
    "            failed_terms.append((search_term, year))\n",
    "\n",
    "    # Update pending terms for the next loop (only failed ones)\n",
    "    pending_terms = failed_terms  \n",
    "\n",
    "    if pending_terms:\n",
    "        print(f\"üîÑ Retrying {len(pending_terms)} failed terms...\")\n",
    "\n",
    "# If all terms are processed, remove the failed_terms.csv\n",
    "if os.path.exists(failed_data_file):\n",
    "    os.remove(failed_data_file)\n",
    "\n",
    "print(\"‚úÖ All terms successfully processed! Check clean_trends_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  Donald Trump  Wikipedia\n",
      "0 2017-01-01            27         17\n",
      "1 2017-01-08            48         18\n",
      "2 2017-01-15           100         18\n",
      "3 2017-01-22            79         20\n",
      "4 2017-01-29            64         19\n"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Define Keywords for comparison\n",
    "keywords = [\"Donald Trump\", \"Wikipedia\"]\n",
    "\n",
    "# Build Payload\n",
    "pytrends.build_payload(keywords, timeframe='2017-01-01 2017-12-31', geo='US')\n",
    "\n",
    "# Get weekly interest over time\n",
    "df_trends = pytrends.interest_over_time()\n",
    "\n",
    "# Remove 'isPartial' column if present\n",
    "if 'isPartial' in df_trends.columns:\n",
    "    df_trends = df_trends.drop(columns=['isPartial'])\n",
    "\n",
    "# Reset index to include date as a column\n",
    "df_trends.reset_index(inplace=True)\n",
    "\n",
    "print(df_trends.head())  # Show first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequestsError",
     "evalue": "The request failed: Google returned a response with code 429",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m pytrends\u001b[38;5;241m.\u001b[39mbuild_payload(keywords, timeframe\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2017-01-01 2017-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m, geo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Get weekly interest over time\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m df_trends \u001b[38;5;241m=\u001b[39m \u001b[43mpytrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Remove 'isPartial' column if present\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misPartial\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_trends\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:232\u001b[0m, in \u001b[0;36mTrendReq.interest_over_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m over_time_payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# convert to string as requests will mangle\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreq\u001b[39m\u001b[38;5;124m'\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtz\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz\n\u001b[1;32m    229\u001b[0m }\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m req_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(req_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimelineData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (df\u001b[38;5;241m.\u001b[39mempty):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:159\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[0;32m--> 159\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[0;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Define Keywords for comparison\n",
    "keywords = [\"Donald Trump\", \"Wikipedia\"]\n",
    "\n",
    "# Build Payload\n",
    "pytrends.build_payload(keywords, timeframe='2017-01-01 2017-12-31', geo='US')\n",
    "\n",
    "# Get weekly interest over time\n",
    "df_trends = pytrends.interest_over_time()\n",
    "\n",
    "# Remove 'isPartial' column if present\n",
    "if 'isPartial' in df_trends.columns:\n",
    "    df_trends = df_trends.drop(columns=['isPartial'])\n",
    "\n",
    "# Reset index to include date as a column\n",
    "df_trends.reset_index(inplace=True)\n",
    "\n",
    "print(df_trends.head())  # Show first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequestsError",
     "evalue": "The request failed: Google returned a response with code 429",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m pytrends\u001b[38;5;241m.\u001b[39mbuild_payload(keywords, timeframe\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2015-01-01 2015-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m, geo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Get weekly interest over time\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m df_trends \u001b[38;5;241m=\u001b[39m \u001b[43mpytrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Remove 'isPartial' column if present\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misPartial\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_trends\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:232\u001b[0m, in \u001b[0;36mTrendReq.interest_over_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m over_time_payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# convert to string as requests will mangle\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreq\u001b[39m\u001b[38;5;124m'\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtz\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz\n\u001b[1;32m    229\u001b[0m }\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m req_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(req_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimelineData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (df\u001b[38;5;241m.\u001b[39mempty):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:159\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[0;32m--> 159\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[0;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Define Keywords for comparison\n",
    "keywords = [\"Bernie Sanders\"]\n",
    "\n",
    "# Build Payload\n",
    "pytrends.build_payload(keywords, timeframe='2015-01-01 2015-12-31', geo='US')\n",
    "\n",
    "# Get weekly interest over time\n",
    "df_trends = pytrends.interest_over_time()\n",
    "\n",
    "# Remove 'isPartial' column if present\n",
    "if 'isPartial' in df_trends.columns:\n",
    "    df_trends = df_trends.drop(columns=['isPartial'])\n",
    "\n",
    "# Reset index to include date as a column\n",
    "df_trends.reset_index(inplace=True)\n",
    "\n",
    "print(df_trends.head())  # Show first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annualised Comp to Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Search Term  Average Interest  Year\n",
      "0  Donald Trump         27.000000  2017\n",
      "1     Wikipedia         17.660377  2017\n"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Define Keywords for comparison\n",
    "keywords = [\"Donald Trump\", \"Wikipedia\"]\n",
    "\n",
    "# Define Year\n",
    "year = \"2017\"\n",
    "\n",
    "# Build Payload\n",
    "pytrends.build_payload(keywords, timeframe=f\"{year}-01-01 {year}-12-31\", geo='US')\n",
    "\n",
    "# Get weekly interest over time\n",
    "df_trends = pytrends.interest_over_time()\n",
    "\n",
    "# Remove 'isPartial' column if present\n",
    "if 'isPartial' in df_trends.columns:\n",
    "    df_trends = df_trends.drop(columns=['isPartial'])\n",
    "\n",
    "# Compute the yearly average interest\n",
    "df_average_interest = df_trends.mean().reset_index()\n",
    "df_average_interest.columns = [\"Search Term\", \"Average Interest\"]\n",
    "\n",
    "# Add Year column\n",
    "df_average_interest[\"Year\"] = year\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_average_interest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract State Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Pytrends\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "\n",
    "# Define Keywords\n",
    "keywords = [\"Kevin Spacey\", \"Wikipedia\"]\n",
    "\n",
    "# Build Payload for comparison\n",
    "pytrends.build_payload(keywords, timeframe='2017-01-01 2017-12-31', geo='US')\n",
    "\n",
    "# Extract Regional Interest\n",
    "df_regions = pytrends.interest_by_region(resolution='REGION')\n",
    "\n",
    "# Normalize as percentages\n",
    "df_regions[\"Total\"] = df_regions.sum(axis=1)\n",
    "df_regions[\"Kevin Spacey %\"] = (df_regions[\"Kevin Spacey\"] / df_regions[\"Total\"]) * 100\n",
    "df_regions[\"Wikipedia %\"] = (df_regions[\"Wikipedia\"] / df_regions[\"Total\"]) * 100\n",
    "\n",
    "# Keep only percentage columns\n",
    "df_regions = df_regions[[\"Kevin Spacey %\", \"Wikipedia %\"]]\n",
    "\n",
    "# Save to CSV\n",
    "df_regions.to_csv(\"state_interest_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequestsError",
     "evalue": "The request failed: Google returned a response with code 429",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m pytrends \u001b[38;5;241m=\u001b[39m TrendReq(hl\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men-US\u001b[39m\u001b[38;5;124m'\u001b[39m, tz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m360\u001b[39m)\n\u001b[1;32m      5\u001b[0m pytrends\u001b[38;5;241m.\u001b[39mbuild_payload([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoogle\u001b[39m\u001b[38;5;124m\"\u001b[39m], timeframe\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnow 1-d\u001b[39m\u001b[38;5;124m\"\u001b[39m, geo\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m df_trends \u001b[38;5;241m=\u001b[39m \u001b[43mpytrends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterest_over_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_trends\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:232\u001b[0m, in \u001b[0;36mTrendReq.interest_over_time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m over_time_payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# convert to string as requests will mangle\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreq\u001b[39m\u001b[38;5;124m'\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterest_over_time_widget[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtz\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz\n\u001b[1;32m    229\u001b[0m }\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# make the request and parse the returned json\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m req_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTEREST_OVER_TIME_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTrendReq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrim_chars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mover_time_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(req_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimelineData\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (df\u001b[38;5;241m.\u001b[39mempty):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pytrends/request.py:159\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m status_codes\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mtoo_many_requests:\n\u001b[0;32m--> 159\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTooManyRequestsError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mResponseError\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "\u001b[0;31mTooManyRequestsError\u001b[0m: The request failed: Google returned a response with code 429"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "pytrends.build_payload([\"Google\"], timeframe=\"now 1-d\", geo='US')\n",
    "\n",
    "df_trends = pytrends.interest_over_time()\n",
    "print(df_trends.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
