{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Define the updated HorizonAnalytics template\n",
    "HorizonAnalytics = go.layout.Template(\n",
    "    layout=go.Layout(\n",
    "        paper_bgcolor='#0d1b2a',  # Background color\n",
    "        plot_bgcolor='#0d1b2a',  # Background color\n",
    "        height=800,\n",
    "        width=800 * 1.618,\n",
    "        xaxis=dict(\n",
    "            anchor='y',\n",
    "            showgrid=True,\n",
    "            gridcolor='rgba(255, 255, 255, 0.2)',  # Softer grid lines for contrast\n",
    "            tickfont=dict(\n",
    "                size=36,  # Consistent with other elements\n",
    "                family='Montserrat, sans-serif',\n",
    "                color='#ffffff',\n",
    "                weight=\"bold\"\n",
    "            ),\n",
    "            title=dict(\n",
    "                text='',\n",
    "                font=dict(\n",
    "                    size=48,  # Increase to match other elements\n",
    "                    family='Montserrat, sans-serif',\n",
    "                    color='#ffffff',\n",
    "                    weight=\"bold\"\n",
    "                )\n",
    "            ),\n",
    "            linecolor='#ffffff',  # White axis lines for contrast\n",
    "            linewidth=2\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            anchor='x',\n",
    "            showgrid=True,\n",
    "            gridcolor='rgba(255, 255, 255, 0.2)',  # Softer grid lines\n",
    "            tickfont=dict(\n",
    "                size=36,  # Consistent with x-axis\n",
    "                family='Montserrat, sans-serif',\n",
    "                color='#ffffff',\n",
    "                weight=\"bold\"\n",
    "            ),\n",
    "            title=dict(\n",
    "                text='',\n",
    "                font=dict(\n",
    "                    size=48,  # Increase to match x-axis\n",
    "                    family='Montserrat, sans-serif',\n",
    "                    color='#ffffff',\n",
    "                    weight=\"bold\"\n",
    "                )\n",
    "            ),\n",
    "            linecolor='#ffffff',  # White axis lines\n",
    "            linewidth=2\n",
    "        ),\n",
    "        font=dict(\n",
    "            color='#ffffff',  # White font for all text\n",
    "            size=36,  # Uniform font size\n",
    "            family='Montserrat, sans-serif',\n",
    "            weight=\"bold\"\n",
    "        ),\n",
    "        # Refined colorway for better visibility and differentiation\n",
    "        colorway=[\"#FFFF00\", \"#33D7FF\", \"#A463FF\", \"#FFD700\", \n",
    "                  \"#ff4081\", \"#ffc107\", \"#00c4a0\", \"#a0aec0\"],\n",
    "        title=dict(\n",
    "            text='',\n",
    "            font=dict(\n",
    "                size=64,  # **Big Boost in Title Size**\n",
    "                color='#ffffff',\n",
    "                family='Montserrat, sans-serif',\n",
    "                weight=\"bold\"\n",
    "            ),\n",
    "            x=0.5,  # Center title\n",
    "            y=0.97  # Push title higher\n",
    "        )\n",
    "    ),\n",
    "    data=dict(\n",
    "        scatter=[\n",
    "            go.Scatter(\n",
    "                line=dict(width=5)  # Increased line width for better visibility\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Register the updated HorizonAnalytics template\n",
    "pio.templates['HorizonAnalytics'] = HorizonAnalytics\n",
    "pio.templates.default = 'HorizonAnalytics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f_nobel_peace: id (year, laureate, country)\n",
    "https://en.wikipedia.org/wiki/List_of_Nobel_Peace_Prize_laureates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Wikipedia URL for Nobel Peace Prize laureates\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_Nobel_Peace_Prize_laureates\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find the first table on the page\n",
    "table = soup.find(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "# Extract data from the table\n",
    "records = []\n",
    "for row in table.find_all(\"tr\")[1:]:  # Skip the header row\n",
    "    cols = row.find_all(\"td\")\n",
    "    if len(cols) >= 5:  # Adjust for colspan in laureate column\n",
    "        year = cols[0].text.strip()\n",
    "        laureate_pic_cell = cols[1].find(\"a\")  # Extract link from the first laureate column (picture)\n",
    "        laureate_name_cell = cols[2].find(\"a\")  # Extract link from the second laureate column (name)\n",
    "        laureate_name = cols[1].text.strip() + \" \" + cols[2].text.strip()  # Merge laureate columns\n",
    "        country_raw = cols[3].text.strip()  # Country is now in the fourth column\n",
    "        \n",
    "        # Remove birth/death years from laureate\n",
    "        laureate = laureate_name.split('(')[0].strip()\n",
    "        \n",
    "        # Extract Wikipedia links\n",
    "        link_pic = urljoin(url, laureate_pic_cell[\"href\"]) if laureate_pic_cell else \"\"\n",
    "        link_name = urljoin(url, laureate_name_cell[\"href\"]) if laureate_name_cell else \"\"\n",
    "        \n",
    "        # Extract only the first country mentioned\n",
    "        country = country_raw.split(\"[\")[0].strip()\n",
    "        \n",
    "        # Handle cases where country might still be missing\n",
    "        if not country:\n",
    "            country = \"Unknown\"\n",
    "        \n",
    "        records.append([year, laureate, country, link_pic, link_name])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(records, columns=[\"year\", \"laureate\", \"country\", \"link_pic\", \"link_name\"])\n",
    "\n",
    "# Remove any empty rows\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df = df[df[\"year\"].str.isnumeric()]  # Ensure year values are valid numbers\n",
    "\n",
    "# Sort by year (ascending), country (ascending), laureate (ascending)\n",
    "df.sort_values(by=[\"year\", \"country\", \"laureate\"], ascending=[True, True, True], inplace=True)\n",
    "\n",
    "# Generate sequential integer ID starting at 1\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.insert(0, \"id\", df.index + 1)  # Insert 'id' as the first column\n",
    "\n",
    "# Save to CSV with the correct output format\n",
    "df.to_csv(\"d_nobel_peace_raw.csv\", index=False, columns=[\"id\", \"laureate\", \"country\", \"year\", \"link_pic\", \"link_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] Updated d_nobel_peace.csv with country_code column.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>laureate</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>year</th>\n",
       "      <th>link_pic</th>\n",
       "      <th>link_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Henry Dunant</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>CHE</td>\n",
       "      <td>1901</td>\n",
       "      <td>https://en.wikipedia.org/wiki/File:Jean_Henri_...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Henry_Dunant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ã‰lie Ducommun</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>CHE</td>\n",
       "      <td>1902</td>\n",
       "      <td>https://en.wikipedia.org/wiki/File:Ducommun.jpg</td>\n",
       "      <td>https://en.wikipedia.org/wiki/%C3%89lie_Ducommun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>William Randal Cremer</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GBR</td>\n",
       "      <td>1903</td>\n",
       "      <td>https://en.wikipedia.org/wiki/File:Cremer.jpg</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Randal_Cremer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Institute of International Law</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>BEL</td>\n",
       "      <td>1904</td>\n",
       "      <td>https://en.wikipedia.org/wiki/File:Logo_of_Ins...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Institut_de_Droi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bertha von Suttner</td>\n",
       "      <td>Austria</td>\n",
       "      <td>AUT</td>\n",
       "      <td>1905</td>\n",
       "      <td>https://en.wikipedia.org/wiki/File:Bertha_von_...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bertha_von_Suttner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>World Food Programme</td>\n",
       "      <td>United Nations</td>\n",
       "      <td>UN</td>\n",
       "      <td>2020</td>\n",
       "      <td>https://en.wikipedia.org/wiki/File:World_Food_...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/World_Food_Progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>102</td>\n",
       "      <td>Maria Ressa</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>PHL</td>\n",
       "      <td>2021</td>\n",
       "      <td>https://en.wikipedia.org/wiki/File:Maria_Ressa...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Maria_Ressa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>Ales Bialiatski</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>BLR</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://en.wikipedia.org/wiki/File:Alaksandr_B...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Ales_Bialiatski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>Narges Mohammadi</td>\n",
       "      <td>Iran</td>\n",
       "      <td>IRN</td>\n",
       "      <td>2023</td>\n",
       "      <td>https://en.wikipedia.org/wiki/File:Narges_Moha...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Narges_Mohammadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>105</td>\n",
       "      <td>Nihon Hidankyo</td>\n",
       "      <td>Japan</td>\n",
       "      <td>JPN</td>\n",
       "      <td>2024</td>\n",
       "      <td>https://en.wikipedia.org/wiki/File:Origami_-_C...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Nihon_Hidankyo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        laureate         country country_code  year  \\\n",
       "0      1                    Henry Dunant     Switzerland          CHE  1901   \n",
       "1      2                   Ã‰lie Ducommun     Switzerland          CHE  1902   \n",
       "2      3           William Randal Cremer  United Kingdom          GBR  1903   \n",
       "3      4  Institute of International Law         Belgium          BEL  1904   \n",
       "4      5              Bertha von Suttner         Austria          AUT  1905   \n",
       "..   ...                             ...             ...          ...   ...   \n",
       "100  101            World Food Programme  United Nations           UN  2020   \n",
       "101  102                     Maria Ressa     Philippines          PHL  2021   \n",
       "102  103                 Ales Bialiatski         Belarus          BLR  2022   \n",
       "103  104                Narges Mohammadi            Iran          IRN  2023   \n",
       "104  105                  Nihon Hidankyo           Japan          JPN  2024   \n",
       "\n",
       "                                              link_pic  \\\n",
       "0    https://en.wikipedia.org/wiki/File:Jean_Henri_...   \n",
       "1      https://en.wikipedia.org/wiki/File:Ducommun.jpg   \n",
       "2        https://en.wikipedia.org/wiki/File:Cremer.jpg   \n",
       "3    https://en.wikipedia.org/wiki/File:Logo_of_Ins...   \n",
       "4    https://en.wikipedia.org/wiki/File:Bertha_von_...   \n",
       "..                                                 ...   \n",
       "100  https://en.wikipedia.org/wiki/File:World_Food_...   \n",
       "101  https://en.wikipedia.org/wiki/File:Maria_Ressa...   \n",
       "102  https://en.wikipedia.org/wiki/File:Alaksandr_B...   \n",
       "103  https://en.wikipedia.org/wiki/File:Narges_Moha...   \n",
       "104  https://en.wikipedia.org/wiki/File:Origami_-_C...   \n",
       "\n",
       "                                             link_name  \n",
       "0           https://en.wikipedia.org/wiki/Henry_Dunant  \n",
       "1     https://en.wikipedia.org/wiki/%C3%89lie_Ducommun  \n",
       "2          https://en.wikipedia.org/wiki/Randal_Cremer  \n",
       "3    https://en.wikipedia.org/wiki/Institut_de_Droi...  \n",
       "4     https://en.wikipedia.org/wiki/Bertha_von_Suttner  \n",
       "..                                                 ...  \n",
       "100  https://en.wikipedia.org/wiki/World_Food_Progr...  \n",
       "101          https://en.wikipedia.org/wiki/Maria_Ressa  \n",
       "102      https://en.wikipedia.org/wiki/Ales_Bialiatski  \n",
       "103     https://en.wikipedia.org/wiki/Narges_Mohammadi  \n",
       "104       https://en.wikipedia.org/wiki/Nihon_Hidankyo  \n",
       "\n",
       "[105 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Mapping of country names to ISO 3166-1 alpha-3 codes\n",
    "country_iso_mapping = {\n",
    "    \"Argentina\": \"ARG\",\n",
    "    \"Austria\": \"AUT\",\n",
    "    \"Bangladesh\": \"BGD\",\n",
    "    \"Belgium\": \"BEL\",\n",
    "    \"Belarus\": \"BLR\",\n",
    "    \"Canada\": \"CAN\",\n",
    "    \"China\": \"CHN\",\n",
    "    \"Colombia\": \"COL\",\n",
    "    \"Costa Rica\": \"CRI\",\n",
    "    \"Czech Republic\": \"CZE\",\n",
    "    \"Democratic Republic of the Congo\": \"COD\",\n",
    "    \"Egypt\": \"EGY\",\n",
    "    \"Ethiopia\": \"ETH\",\n",
    "    \"European Union\": \"EU\",  # Not an official ISO code, but useful\n",
    "    \"East Timor\": \"TLS\",  # Officially known as Timor-Leste\n",
    "    \"Finland\": \"FIN\",\n",
    "    \"France\": \"FRA\",\n",
    "    \"Germany\": \"DEU\",\n",
    "    \"Guatemala\": \"GTM\",\n",
    "    \"India\": \"IND\",\n",
    "    \"Iran\": \"IRN\",\n",
    "    \"Ireland\": \"IRL\",\n",
    "    \"Israel\": \"ISR\",\n",
    "    \"Italy\": \"ITA\",\n",
    "    \"Japan\": \"JPN\",\n",
    "    \"Kenya\": \"KEN\",\n",
    "    \"Liberia\": \"LBR\",\n",
    "    \"Myanmar\": \"MMR\",\n",
    "    \"Netherlands\": \"NLD\",\n",
    "    \"Norway\": \"NOR\",\n",
    "    \"Palestine\": \"PSE\",\n",
    "    \"Philippines\": \"PHL\",\n",
    "    \"Poland\": \"POL\",\n",
    "    \"Russia\": \"RUS\",\n",
    "    \"Serbia\": \"SRB\",\n",
    "    \"South Africa\": \"ZAF\",\n",
    "    \"South Korea\": \"KOR\",\n",
    "    \"Sweden\": \"SWE\",\n",
    "    \"Switzerland\": \"CHE\",\n",
    "    \"Tunisia\": \"TUN\",\n",
    "    \"Turkey\": \"TUR\",\n",
    "    \"United Kingdom\": \"GBR\",\n",
    "    \"United States\": \"USA\",\n",
    "    \"United States;United Kingdom\": \"USA;UK\",  # Assuming first country is primary\n",
    "    \"United Nations\": \"UN\"  # For organizations\n",
    "}\n",
    "\n",
    "def update_nobel_peace_data(csv_file):\n",
    "    try:\n",
    "        # Read CSV with proper handling of quotes\n",
    "        df = pd.read_csv(csv_file, quotechar='\"', on_bad_lines='skip')\n",
    "\n",
    "        # Standardize \"Other: ...\" cases to \"United Nations\"\n",
    "        df[\"country\"] = df[\"country\"].apply(lambda x: \"United Nations\" if str(x).startswith(\"Other:\") else x)\n",
    "\n",
    "        # Map countries to their ISO 3166-1 alpha-3 codes\n",
    "        df[\"country_code\"] = df[\"country\"].map(country_iso_mapping)\n",
    "\n",
    "        # Find unmatched countries\n",
    "        unmatched_countries = df[df[\"country_code\"].isna()][\"country\"].unique()\n",
    "        \n",
    "        if len(unmatched_countries) > 0:\n",
    "            print(\"[WARNING] Unmatched countries found:\")\n",
    "            for country in unmatched_countries:\n",
    "                print(f\" - {country}\")\n",
    "\n",
    "        # Reorder columns to insert 'country_code' immediately after 'country'\n",
    "        cols = list(df.columns)\n",
    "        cols.insert(cols.index(\"country\") + 1, cols.pop(cols.index(\"country_code\")))\n",
    "        df = df[cols]\n",
    "\n",
    "        # Save changes to the original file\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"[SUCCESS] Updated {csv_file} with country_code column.\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to update CSV: {e}\")\n",
    "\n",
    "# Run the function to update the file\n",
    "update_nobel_peace_data(\"d_nobel_peace.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nobel pics based on 'laureate' link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, unquote\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def extract_nobel_peace_pictures(csv_file, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    df = pd.read_csv(csv_file)\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[\"link_pic\"]) or row[\"link_pic\"].strip() == \"\":\n",
    "            print(f\"[SKIP] No image link found for {row['laureate']}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"[PROCESSING] {row['laureate']} - Link: {row['link_pic']}\")\n",
    "        \n",
    "        response = requests.get(row[\"link_pic\"], headers=headers, allow_redirects=True)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"[ERROR] Failed to access {row['link_pic']} (Status Code: {response.status_code})\")\n",
    "            continue\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # Extract the full image URL from the media file page\n",
    "        image_div = soup.find(\"div\", {\"class\": \"fullImageLink\"})\n",
    "        if image_div:\n",
    "            img_tag = image_div.find(\"a\")\n",
    "            if img_tag and \"href\" in img_tag.attrs:\n",
    "                img_url = urljoin(\"https://upload.wikimedia.org/wikipedia/commons/\", unquote(img_tag[\"href\"]))\n",
    "                print(f\"[FOUND] Image URL: {img_url}\")\n",
    "            else:\n",
    "                print(f\"[ERROR] No valid image link found inside fullImageLink for {row['laureate']}\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"[ERROR] No fullImageLink div found for {row['laureate']}\")\n",
    "            continue\n",
    "        \n",
    "        # Detect SVG files and save them directly\n",
    "        if img_url.endswith(\".svg\"):\n",
    "            svg_path = os.path.join(output_folder, f\"{row['id']}.svg\")\n",
    "            svg_response = requests.get(img_url, headers=headers, stream=True)\n",
    "            if svg_response.status_code == 200:\n",
    "                with open(svg_path, \"wb\") as f:\n",
    "                    f.write(svg_response.content)\n",
    "                print(f\"[SUCCESS] Saved SVG image for {row['laureate']} as {svg_path}\")\n",
    "            else:\n",
    "                print(f\"[ERROR] Failed to download SVG for {row['laureate']}\")\n",
    "            continue  # Skip further processing for SVGs\n",
    "        \n",
    "        # Download and verify the image\n",
    "        img_response = requests.get(img_url, headers=headers, stream=True)\n",
    "        if img_response.status_code != 200:\n",
    "            print(f\"[ERROR] Failed to download image for {row['laureate']} (Status Code: {img_response.status_code})\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(BytesIO(img_response.content))\n",
    "            img_path = os.path.join(output_folder, f\"{row['id']}.png\")\n",
    "            img.save(img_path, \"PNG\")\n",
    "            print(f\"[SUCCESS] Saved image for {row['laureate']} as {img_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Processing image for {row['laureate']}: {e}\")\n",
    "\n",
    "# Call the function with the appropriate parameters\n",
    "extract_nobel_peace_pictures(\"d_nobel_peace.csv\", \"/Users/arya/Documents/Adobe/Premiere Pro/Horizon Analytics/2025-03_assemble_nobel_peace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
